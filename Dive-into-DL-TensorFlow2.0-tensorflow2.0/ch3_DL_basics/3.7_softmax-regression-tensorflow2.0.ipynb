#%% md

我们在“线性回归的简洁实现”一节中已经了解了使用tensorflow2.0实现模型的便利。下面，让我们再次使用Gluon来实现一个softmax回归模型。首先导入所需的包或模块。

#%%

import tensorflow as tf

#%% md

3.7.1. 获取和读取数据¶
我们仍然使用Fashion-MNIST数据集和上一节中设置的批量大小。

#%%

from tensorflow import keras
fashion_mnist = keras.datasets.fashion_mnist
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

#%% md

对数据进行处理，归一化，便于训练

#%%

x_train = x_train / 255.0
x_test = x_test / 255.0

#%% md

在“softmax回归”一节中提到，softmax回归的输出层是一个全连接层。因此，我们添加一个输出个数为10的全连接层。
第一层是Flatten，将28 * 28的像素值，压缩成一行 (784, )
第二层还是Dense，因为是多分类问题，激活函数使用softmax

#%%

from tensorflow import keras
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(10, activation=tf.nn.softmax)
])

#%% md

使用交叉熵损失函数和学习率为0.1的小批量随机梯度下降作为优化算法对模型进行训练

#%%

model.compile(optimizer=tf.keras.optimizers.SGD(0.1),
              loss = 'sparse_categorical_crossentropy',
              metrics=['accuracy'])

#%% md

选用batch的大小为256，对模型进行训练

#%%

model.fit(x_train,y_train,epochs=5,batch_size=256)

#%% md

接下来，比较模型在测试数据集上的表现情况

#%%

test_loss, test_acc = model.evaluate(x_test, y_test)
print('Test Acc:',test_acc)

#%%


